{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os\nfrom os.path import isfile, join\nimport numpy as np\nimport shutil\nfrom tensorflow import keras\nfrom pathlib import Path\nfrom IPython.display import display, Audio\nimport subprocess","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-30T06:56:29.698926Z","iopub.execute_input":"2022-12-30T06:56:29.699299Z","iopub.status.idle":"2022-12-30T06:56:35.151097Z","shell.execute_reply.started":"2022-12-30T06:56:29.699173Z","shell.execute_reply":"2022-12-30T06:56:35.150270Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Copy dataset to arrange audio and noise in different folders","metadata":{}},{"cell_type":"code","source":"!cp -r \"../input/speaker-recognition-dataset\" ./","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:56:35.153147Z","iopub.execute_input":"2022-12-30T06:56:35.153695Z","iopub.status.idle":"2022-12-30T06:57:05.047187Z","shell.execute_reply.started":"2022-12-30T06:56:35.153655Z","shell.execute_reply":"2022-12-30T06:57:05.046103Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Get the data directories","metadata":{}},{"cell_type":"code","source":"\ndata_directory = \"./speaker-recognition-dataset/16000_pcm_speeches\"\naudio_folder = \"audio\"\nnoise_folder = \"noise\"\n\naudio_path = os.path.join(data_directory, audio_folder)\nnoise_path = os.path.join(data_directory, noise_folder)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:05.050770Z","iopub.execute_input":"2022-12-30T06:57:05.051037Z","iopub.status.idle":"2022-12-30T06:57:05.056387Z","shell.execute_reply.started":"2022-12-30T06:57:05.051005Z","shell.execute_reply":"2022-12-30T06:57:05.055501Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"audio_path","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:05.058883Z","iopub.execute_input":"2022-12-30T06:57:05.059194Z","iopub.status.idle":"2022-12-30T06:57:05.071852Z","shell.execute_reply.started":"2022-12-30T06:57:05.059150Z","shell.execute_reply":"2022-12-30T06:57:05.071025Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'./speaker-recognition-dataset/16000_pcm_speeches/audio'"},"metadata":{}}]},{"cell_type":"markdown","source":"set all the parameters for training and other purposes","metadata":{}},{"cell_type":"code","source":"valid_split = 0.1\n\nshuffle_seed = 43\n\nsample_rate = 16000\n\nscale = 0.5\n\nbatch_size = 128\n\nepochs = 15","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:05.073353Z","iopub.execute_input":"2022-12-30T06:57:05.073619Z","iopub.status.idle":"2022-12-30T06:57:05.081404Z","shell.execute_reply.started":"2022-12-30T06:57:05.073584Z","shell.execute_reply":"2022-12-30T06:57:05.080495Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"arrange audio and noise","metadata":{}},{"cell_type":"code","source":"for folder in os.listdir(data_directory):\n    if os.path.isdir(os.path.join(data_directory, folder)):\n        if folder in [audio_folder, noise_folder]:\n            \n            continue\n        elif folder in [\"other\", \"_background_noise_\"]:\n            \n            shutil.move(\n                os.path.join(data_directory, folder),\n                os.path.join(noise_path, folder),\n            )\n        else:\n            shutil.move(\n                os.path.join(data_directory, folder),\n                os.path.join(audio_path, folder),\n            )\n","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:05.084668Z","iopub.execute_input":"2022-12-30T06:57:05.084911Z","iopub.status.idle":"2022-12-30T06:57:05.364323Z","shell.execute_reply.started":"2022-12-30T06:57:05.084882Z","shell.execute_reply":"2022-12-30T06:57:05.363540Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Get the list of all noise files","metadata":{}},{"cell_type":"code","source":"\nnoise_paths = []\nfor subdir in os.listdir(noise_path):\n    subdir_path = Path(noise_path) / subdir\n    if os.path.isdir(subdir_path):\n        noise_paths += [\n            os.path.join(subdir_path, filepath)\n            for filepath in os.listdir(subdir_path)\n            if filepath.endswith(\".wav\")\n        ]","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:05.367051Z","iopub.execute_input":"2022-12-30T06:57:05.367541Z","iopub.status.idle":"2022-12-30T06:57:05.373922Z","shell.execute_reply.started":"2022-12-30T06:57:05.367501Z","shell.execute_reply":"2022-12-30T06:57:05.373148Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"noise_paths","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:05.375290Z","iopub.execute_input":"2022-12-30T06:57:05.375662Z","iopub.status.idle":"2022-12-30T06:57:05.387009Z","shell.execute_reply.started":"2022-12-30T06:57:05.375620Z","shell.execute_reply":"2022-12-30T06:57:05.386254Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['speaker-recognition-dataset/16000_pcm_speeches/noise/other/exercise_bike.wav',\n 'speaker-recognition-dataset/16000_pcm_speeches/noise/other/pink_noise.wav',\n 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/running_tap.wav',\n 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/doing_the_dishes.wav',\n 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/dude_miaowing.wav',\n 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/10convert.com_Audience-Claps_daSG5fwdA7o.wav']"},"metadata":{}}]},{"cell_type":"markdown","source":"**Split noise into chunks of 16,000 steps each**","metadata":{}},{"cell_type":"code","source":"command = (\n    \"for dir in `ls -1 \" + noise_path + \"`; do \"\n    \"for file in `ls -1 \" + noise_path + \"/$dir/*.wav`; do \"\n    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n    \"$file | grep sample_rate | cut -f2 -d=`; \"\n    \"if [ $sample_rate -ne 16000 ]; then \"\n    \"ffmpeg -hide_banner -loglevel panic -y \"\n    \"-i $file -ar 16000 temp.wav; \"\n    \"mv temp.wav $file; \"\n    \"fi; done; done\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:05.390050Z","iopub.execute_input":"2022-12-30T06:57:05.390277Z","iopub.status.idle":"2022-12-30T06:57:05.397059Z","shell.execute_reply.started":"2022-12-30T06:57:05.390250Z","shell.execute_reply":"2022-12-30T06:57:05.396251Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"os.system(command)\ndef load_noise_sample(path):\n    sample, sampling_rate = tf.audio.decode_wav(\n        tf.io.read_file(path), desired_channels=1\n    )\n    if sampling_rate == sample_rate:\n        slices = int(sample.shape[0] / sample_rate)\n        sample = tf.split(sample[: slices * sample_rate], slices)\n        return sample\n    else:\n        print(\"Sampling rate for\",path, \"is incorrect\")\n        return None\n\n\nnoises = []\nfor path in noise_paths:\n    sample = load_noise_sample(path)\n    if sample:\n        noises.extend(sample)\nnoises = tf.stack(noises)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:05.401373Z","iopub.execute_input":"2022-12-30T06:57:05.401773Z","iopub.status.idle":"2022-12-30T06:57:11.526911Z","shell.execute_reply.started":"2022-12-30T06:57:05.401743Z","shell.execute_reply":"2022-12-30T06:57:11.526094Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2022-12-30 06:57:07.916835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:07.917894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:08.025979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:08.026880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:08.027733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:08.028525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:08.031257: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-30 06:57:08.295035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:08.295992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:08.296923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:08.297734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:08.298452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:08.299197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:11.025823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:11.026814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:11.027623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:11.028365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:11.029157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:11.029888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13795 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-12-30 06:57:11.032491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-30 06:57:11.033263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13795 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**DATASET GENERATION**","metadata":{}},{"cell_type":"code","source":"def paths_and_labels_to_dataset(audio_paths, labels):\n    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n    return tf.data.Dataset.zip((audio_ds, label_ds))","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:11.529073Z","iopub.execute_input":"2022-12-30T06:57:11.529558Z","iopub.status.idle":"2022-12-30T06:57:11.536015Z","shell.execute_reply.started":"2022-12-30T06:57:11.529515Z","shell.execute_reply":"2022-12-30T06:57:11.535152Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def path_to_audio(path):\n    audio = tf.io.read_file(path)\n    audio, _ = tf.audio.decode_wav(audio, 1, sample_rate)\n    return audio","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:11.538419Z","iopub.execute_input":"2022-12-30T06:57:11.538637Z","iopub.status.idle":"2022-12-30T06:57:11.547948Z","shell.execute_reply.started":"2022-12-30T06:57:11.538610Z","shell.execute_reply":"2022-12-30T06:57:11.547094Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**add noise to dataset**","metadata":{}},{"cell_type":"code","source":"def add_noise(audio, noises=None, scale=0.5):\n    if noises is not None:\n        tf_rnd = tf.random.uniform(\n            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n        )\n        noise = tf.gather(noises, tf_rnd, axis=0)\n\n        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n\n        audio = audio + noise * prop * scale\n\n    return audio","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:11.549347Z","iopub.execute_input":"2022-12-30T06:57:11.549632Z","iopub.status.idle":"2022-12-30T06:57:11.558546Z","shell.execute_reply.started":"2022-12-30T06:57:11.549593Z","shell.execute_reply":"2022-12-30T06:57:11.557750Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def audio_to_fft(audio):\n    audio = tf.squeeze(audio, axis=-1)\n    fft = tf.signal.fft(\n        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n    )\n    fft = tf.expand_dims(fft, axis=-1)\n\n    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:11.559659Z","iopub.execute_input":"2022-12-30T06:57:11.559975Z","iopub.status.idle":"2022-12-30T06:57:11.569554Z","shell.execute_reply.started":"2022-12-30T06:57:11.559941Z","shell.execute_reply":"2022-12-30T06:57:11.568792Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\nclass_names = os.listdir(audio_path)\nprint(class_names,)\n\naudio_paths = []\nlabels = []\nfor label, name in enumerate(class_names):\n    print(\"Speaker:\",(name))\n    dir_path = Path(audio_path) / name\n    speaker_sample_paths = [\n        os.path.join(dir_path, filepath)\n        for filepath in os.listdir(dir_path)\n        if filepath.endswith(\".wav\")\n    ]\n    audio_paths += speaker_sample_paths\n    labels += [label] * len(speaker_sample_paths)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:11.570801Z","iopub.execute_input":"2022-12-30T06:57:11.571057Z","iopub.status.idle":"2022-12-30T06:57:11.603167Z","shell.execute_reply.started":"2022-12-30T06:57:11.571025Z","shell.execute_reply":"2022-12-30T06:57:11.602489Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"['Jens_Stoltenberg', 'Benjamin_Netanyau', 'Magaret_Tarcher', 'Julia_Gillard', 'Nelson_Mandela']\nSpeaker: Jens_Stoltenberg\nSpeaker: Benjamin_Netanyau\nSpeaker: Magaret_Tarcher\nSpeaker: Julia_Gillard\nSpeaker: Nelson_Mandela\n","output_type":"stream"}]},{"cell_type":"code","source":"# Shuffle to generate random data\nrng = np.random.RandomState(shuffle_seed)\nrng.shuffle(audio_paths)\nrng = np.random.RandomState(shuffle_seed)\nrng.shuffle(labels)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:11.604471Z","iopub.execute_input":"2022-12-30T06:57:11.604730Z","iopub.status.idle":"2022-12-30T06:57:11.612264Z","shell.execute_reply.started":"2022-12-30T06:57:11.604696Z","shell.execute_reply":"2022-12-30T06:57:11.611487Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Split into training and validation\nnum_val_samples = int(valid_split * len(audio_paths))\ntrain_audio_paths = audio_paths[:-num_val_samples]\ntrain_labels = labels[:-num_val_samples]\n\n\nvalid_audio_paths = audio_paths[-num_val_samples:]\nvalid_labels = labels[-num_val_samples:]","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:11.613491Z","iopub.execute_input":"2022-12-30T06:57:11.613806Z","iopub.status.idle":"2022-12-30T06:57:11.624339Z","shell.execute_reply.started":"2022-12-30T06:57:11.613770Z","shell.execute_reply":"2022-12-30T06:57:11.623529Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Create datasets, one for training and the other for validation\ntrain_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\ntrain_ds = train_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n    batch_size\n)\n\nvalid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\nvalid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=shuffle_seed).batch(32)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:11.626722Z","iopub.execute_input":"2022-12-30T06:57:11.626976Z","iopub.status.idle":"2022-12-30T06:57:11.813566Z","shell.execute_reply.started":"2022-12-30T06:57:11.626939Z","shell.execute_reply":"2022-12-30T06:57:11.812789Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**feature Extraction**","metadata":{}},{"cell_type":"code","source":"# Add noise to the training set\ntrain_ds = train_ds.map(\n    lambda x, y: (add_noise(x, noises, scale=scale), y),\n    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n)\n\n# Transform audio wave to the frequency domain using `audio_to_fft`\ntrain_ds = train_ds.map(\n    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\n\ntrain_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n\nvalid_ds = valid_ds.map(\n    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\nvalid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:11.815126Z","iopub.execute_input":"2022-12-30T06:57:11.815422Z","iopub.status.idle":"2022-12-30T06:57:12.121663Z","shell.execute_reply.started":"2022-12-30T06:57:11.815385Z","shell.execute_reply":"2022-12-30T06:57:12.120899Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**Model**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv1D","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:12.123263Z","iopub.execute_input":"2022-12-30T06:57:12.123673Z","iopub.status.idle":"2022-12-30T06:57:13.050588Z","shell.execute_reply.started":"2022-12-30T06:57:12.123637Z","shell.execute_reply":"2022-12-30T06:57:13.049787Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def residual_block(x, filters, conv_num = 3, activation = \"relu\"):\n    s = keras.layers.Conv1D(filters, 1, padding = \"same\")(x)\n    \n    for i in range(conv_num - 1):\n        x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n        x = keras.layers.Activation(activation)(x)\n    \n    x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n    x = keras.layers.Add()([x, s])\n    x = keras.layers.Activation(activation)(x)\n    \n    return keras.layers.MaxPool1D(pool_size = 2, strides = 2)(x)\n\ndef build_model(input_shape, num_classes):\n    inputs = keras.layers.Input(shape = input_shape, name = \"input\")\n    \n    x = residual_block(inputs, 16, 2)\n    x = residual_block(inputs, 32, 2)\n    x = residual_block(inputs, 64, 3)\n    x = residual_block(inputs, 128, 3)\n    x = residual_block(inputs, 128, 3)\n    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n    x = keras.layers.Flatten()(x)\n    x = keras.layers.Dense(256, activation=\"relu\")(x)\n    x = keras.layers.Dense(128, activation=\"relu\")(x)\n    \n    outputs = keras.layers.Dense(num_classes, activation = \"softmax\", name = \"output\")(x)\n    \n    return keras.models.Model(inputs = inputs, outputs = outputs)\n\nmodel = build_model((sample_rate // 2, 1), len(class_names))\n\nmodel.summary()\n\nmodel.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n\nmodel_save_filename = \"model.h5\"\n\nearlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n\nmdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(model_save_filename, monitor=\"val_accuracy\", save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:13.052009Z","iopub.execute_input":"2022-12-30T06:57:13.052316Z","iopub.status.idle":"2022-12-30T06:57:13.395064Z","shell.execute_reply.started":"2022-12-30T06:57:13.052272Z","shell.execute_reply":"2022-12-30T06:57:13.394260Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput (InputLayer)              [(None, 8000, 1)]    0                                            \n__________________________________________________________________________________________________\nconv1d_15 (Conv1D)              (None, 8000, 128)    512         input[0][0]                      \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 8000, 128)    0           conv1d_15[0][0]                  \n__________________________________________________________________________________________________\nconv1d_16 (Conv1D)              (None, 8000, 128)    49280       activation_10[0][0]              \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 8000, 128)    0           conv1d_16[0][0]                  \n__________________________________________________________________________________________________\nconv1d_17 (Conv1D)              (None, 8000, 128)    49280       activation_11[0][0]              \n__________________________________________________________________________________________________\nconv1d_14 (Conv1D)              (None, 8000, 128)    256         input[0][0]                      \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 8000, 128)    0           conv1d_17[0][0]                  \n                                                                 conv1d_14[0][0]                  \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 8000, 128)    0           add_4[0][0]                      \n__________________________________________________________________________________________________\nmax_pooling1d_4 (MaxPooling1D)  (None, 4000, 128)    0           activation_12[0][0]              \n__________________________________________________________________________________________________\naverage_pooling1d (AveragePooli (None, 1333, 128)    0           max_pooling1d_4[0][0]            \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 170624)       0           average_pooling1d[0][0]          \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 256)          43680000    flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n__________________________________________________________________________________________________\noutput (Dense)                  (None, 5)            645         dense_1[0][0]                    \n==================================================================================================\nTotal params: 43,812,869\nTrainable params: 43,812,869\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Training**","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    epochs=epochs,\n    validation_data=valid_ds,\n    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T06:57:13.396681Z","iopub.execute_input":"2022-12-30T06:57:13.396961Z","iopub.status.idle":"2022-12-30T07:19:03.745613Z","shell.execute_reply.started":"2022-12-30T06:57:13.396923Z","shell.execute_reply":"2022-12-30T07:19:03.744774Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2022-12-30 06:57:13.475731: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"2022-12-30 06:57:18.967380: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"53/53 [==============================] - 86s 1s/step - loss: 15.6861 - accuracy: 0.5584 - val_loss: 0.4844 - val_accuracy: 0.8333\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/15\n53/53 [==============================] - 81s 1s/step - loss: 0.2386 - accuracy: 0.9218 - val_loss: 0.2328 - val_accuracy: 0.9080\nEpoch 3/15\n53/53 [==============================] - 78s 1s/step - loss: 0.1581 - accuracy: 0.9418 - val_loss: 0.1626 - val_accuracy: 0.9427\nEpoch 4/15\n53/53 [==============================] - 78s 1s/step - loss: 0.1463 - accuracy: 0.9487 - val_loss: 0.1403 - val_accuracy: 0.9480\nEpoch 5/15\n53/53 [==============================] - 76s 1s/step - loss: 0.0867 - accuracy: 0.9674 - val_loss: 0.1060 - val_accuracy: 0.9693\nEpoch 6/15\n53/53 [==============================] - 76s 1s/step - loss: 0.0932 - accuracy: 0.9670 - val_loss: 0.0992 - val_accuracy: 0.9600\nEpoch 7/15\n53/53 [==============================] - 75s 1s/step - loss: 0.0987 - accuracy: 0.9650 - val_loss: 0.0548 - val_accuracy: 0.9827\nEpoch 8/15\n53/53 [==============================] - 73s 1s/step - loss: 0.0611 - accuracy: 0.9796 - val_loss: 0.0766 - val_accuracy: 0.9707\nEpoch 9/15\n53/53 [==============================] - 72s 1s/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0666 - val_accuracy: 0.9760\nEpoch 10/15\n53/53 [==============================] - 72s 1s/step - loss: 0.0498 - accuracy: 0.9824 - val_loss: 0.0929 - val_accuracy: 0.9680\nEpoch 11/15\n53/53 [==============================] - 70s 1s/step - loss: 0.0439 - accuracy: 0.9842 - val_loss: 0.0562 - val_accuracy: 0.9813\nEpoch 12/15\n53/53 [==============================] - 70s 1s/step - loss: 0.0483 - accuracy: 0.9819 - val_loss: 0.0832 - val_accuracy: 0.9760\nEpoch 13/15\n53/53 [==============================] - 70s 1s/step - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.0691 - val_accuracy: 0.9773\nEpoch 14/15\n53/53 [==============================] - 71s 1s/step - loss: 0.0446 - accuracy: 0.9843 - val_loss: 0.1397 - val_accuracy: 0.9547\nEpoch 15/15\n53/53 [==============================] - 69s 1s/step - loss: 0.0455 - accuracy: 0.9830 - val_loss: 0.0517 - val_accuracy: 0.9867\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Accuracy**","metadata":{}},{"cell_type":"code","source":"print(\"Accuracy of model:\",model.evaluate(valid_ds))","metadata":{"execution":{"iopub.status.busy":"2022-12-30T07:19:03.747279Z","iopub.execute_input":"2022-12-30T07:19:03.747550Z","iopub.status.idle":"2022-12-30T07:19:14.004245Z","shell.execute_reply.started":"2022-12-30T07:19:03.747515Z","shell.execute_reply":"2022-12-30T07:19:14.003291Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"24/24 [==============================] - 7s 268ms/step - loss: 0.0517 - accuracy: 0.9867\nAccuracy of model: [0.051710061728954315, 0.9866666793823242]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Predict**","metadata":{}},{"cell_type":"code","source":"SAMPLES_TO_DISPLAY = 10\n\ntest_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\ntest_ds = test_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n    batch_size\n)\n\ntest_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n\nfor audios, labels in test_ds.take(1):\n    ffts = audio_to_fft(audios)\n    y_pred = model.predict(ffts)\n    rnd = np.random.randint(0, batch_size, SAMPLES_TO_DISPLAY)\n    audios = audios.numpy()[rnd, :, :]\n    labels = labels.numpy()[rnd]\n    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n\n    for index in range(SAMPLES_TO_DISPLAY):\n        print(\n            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n                class_names[labels[index]],\n                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n                class_names[y_pred[index]],\n            )\n        )\n        if labels[index] ==y_pred[index]:\n            print(\"Welcome\")\n        else:\n            print(\"Sorry\")\n        print(\"The speaker is\" if labels[index] == y_pred[index] else \"\", class_names[y_pred[index]])","metadata":{"execution":{"iopub.status.busy":"2022-12-30T07:19:14.006033Z","iopub.execute_input":"2022-12-30T07:19:14.006322Z","iopub.status.idle":"2022-12-30T07:19:15.233848Z","shell.execute_reply.started":"2022-12-30T07:19:14.006284Z","shell.execute_reply":"2022-12-30T07:19:15.233096Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Speaker:\u001b[92m Magaret_Tarcher\u001b[0m\tPredicted:\u001b[92m Magaret_Tarcher\u001b[0m\nWelcome\nThe speaker is Magaret_Tarcher\nSpeaker:\u001b[92m Magaret_Tarcher\u001b[0m\tPredicted:\u001b[92m Magaret_Tarcher\u001b[0m\nWelcome\nThe speaker is Magaret_Tarcher\nSpeaker:\u001b[92m Jens_Stoltenberg\u001b[0m\tPredicted:\u001b[92m Jens_Stoltenberg\u001b[0m\nWelcome\nThe speaker is Jens_Stoltenberg\nSpeaker:\u001b[92m Benjamin_Netanyau\u001b[0m\tPredicted:\u001b[92m Benjamin_Netanyau\u001b[0m\nWelcome\nThe speaker is Benjamin_Netanyau\nSpeaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\nWelcome\nThe speaker is Nelson_Mandela\nSpeaker:\u001b[92m Magaret_Tarcher\u001b[0m\tPredicted:\u001b[92m Magaret_Tarcher\u001b[0m\nWelcome\nThe speaker is Magaret_Tarcher\nSpeaker:\u001b[92m Magaret_Tarcher\u001b[0m\tPredicted:\u001b[92m Magaret_Tarcher\u001b[0m\nWelcome\nThe speaker is Magaret_Tarcher\nSpeaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\nWelcome\nThe speaker is Nelson_Mandela\nSpeaker:\u001b[91m Benjamin_Netanyau\u001b[0m\tPredicted:\u001b[91m Magaret_Tarcher\u001b[0m\nSorry\n Magaret_Tarcher\nSpeaker:\u001b[92m Julia_Gillard\u001b[0m\tPredicted:\u001b[92m Julia_Gillard\u001b[0m\nWelcome\nThe speaker is Julia_Gillard\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Predcit the speaker from the test dataset for real time pred.**","metadata":{}},{"cell_type":"code","source":" def paths_to_dataset(audio_paths):\n    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n    return tf.data.Dataset.zip((path_ds))\n\ndef predict(path, labels):\n    test = paths_and_labels_to_dataset(path, labels)\n\n\n    test = test.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n    batch_size\n    )\n    test = test.prefetch(tf.data.experimental.AUTOTUNE)\n\n\n    test = test.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n\n    for audios, labels in test.take(1):\n        ffts = audio_to_fft(audios)\n        y_pred = model.predict(ffts)\n        rnd = np.random.randint(0, 1, 1)\n        audios = audios.numpy()[rnd, :]\n        labels = labels.numpy()[rnd]\n        y_pred = np.argmax(y_pred, axis=-1)[rnd]\n\n    for index in range(1):\n            print(\n            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n            \"[92m\",y_pred[index],\n                \"[92m\", y_pred[index]\n                )\n            )\n            \n            print(\"Speaker Predicted:\",class_names[y_pred[index]])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-30T07:19:15.235511Z","iopub.execute_input":"2022-12-30T07:19:15.235793Z","iopub.status.idle":"2022-12-30T07:19:15.244429Z","shell.execute_reply.started":"2022-12-30T07:19:15.235760Z","shell.execute_reply":"2022-12-30T07:19:15.243426Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"path = [\"../input/speaker-recognition-dataset/16000_pcm_speeches/Jens_Stoltenberg/1013.wav\"]\nlabels = [\"unknown\"]\ntry:\n    predict(path, labels)\nexcept:\n    print(\"Error! Check if the file correctly passed or not!\")","metadata":{"execution":{"iopub.status.busy":"2022-12-30T07:19:15.245910Z","iopub.execute_input":"2022-12-30T07:19:15.246248Z","iopub.status.idle":"2022-12-30T07:19:15.534616Z","shell.execute_reply.started":"2022-12-30T07:19:15.246200Z","shell.execute_reply":"2022-12-30T07:19:15.533857Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Speaker:\u001b[92m 0\u001b[0m\tPredicted:\u001b[92m 0\u001b[0m\nSpeaker Predicted: Jens_Stoltenberg\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}