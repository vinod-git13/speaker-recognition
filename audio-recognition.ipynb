{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport cupy as np # linear algebra\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-23T10:18:11.787009Z","iopub.execute_input":"2022-12-23T10:18:11.787999Z","iopub.status.idle":"2022-12-23T10:18:14.464974Z","shell.execute_reply.started":"2022-12-23T10:18:11.787882Z","shell.execute_reply":"2022-12-23T10:18:14.464182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rsync -av /kaggle/input/speaker-recognition-dataset/16000_pcm_speeches train","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:18:14.466755Z","iopub.execute_input":"2022-12-23T10:18:14.467052Z","iopub.status.idle":"2022-12-23T10:18:54.926246Z","shell.execute_reply.started":"2022-12-23T10:18:14.467024Z","shell.execute_reply":"2022-12-23T10:18:54.925300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nfrom os.path import isfile, join\nimport numpy as np\nimport shutil\nfrom tensorflow import keras\nfrom pathlib import Path\nfrom IPython.display import display, Audio\nfrom tensorflow.keras.layers import Conv1D\nimport subprocess\nimport numpy","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:18:54.929102Z","iopub.execute_input":"2022-12-23T10:18:54.930030Z","iopub.status.idle":"2022-12-23T10:19:00.850541Z","shell.execute_reply.started":"2022-12-23T10:18:54.929985Z","shell.execute_reply":"2022-12-23T10:19:00.849778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define Variables","metadata":{}},{"cell_type":"code","source":"dataset = os.path.join( \"train/16000_pcm_speeches\")\n\naudios = 'audio'\nnoises = 'noise'\n\nDATASET_AUDIOS_PATH = os.path.join(dataset, audios)\nDATASET_NOISES_PATH = os.path.join(dataset, noises)\n\n\nVALID_SPLIT = 0.1\n\nSHUFFLE_SEED = 43\n\nSAMPLING_RATE = 16000\n\nSCALE = 0.5\n\nBATCH_SIZE = 128\nEPOCHS = 25","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:00.853122Z","iopub.execute_input":"2022-12-23T10:19:00.853391Z","iopub.status.idle":"2022-12-23T10:19:00.863176Z","shell.execute_reply.started":"2022-12-23T10:19:00.853356Z","shell.execute_reply":"2022-12-23T10:19:00.858502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Arrange Audio and Noise","metadata":{}},{"cell_type":"code","source":"if os.path.exists(DATASET_AUDIOS_PATH) is False:\n    os.makedirs(DATASET_AUDIOS_PATH)\n\nif tf.io.gfile.exists(DATASET_NOISES_PATH) is False:\n    tf.io.gfile.makedirs(DATASET_NOISES_PATH)\n\nfor folder in os.listdir(dataset):\n    if os.path.isdir(os.path.join(dataset, folder)):\n        if folder in [audios, noises]:\n            \n            continue\n        elif folder in [\"other\", \"_background_noise_\"]:\n            \n            shutil.move(\n                os.path.join(dataset, folder),\n                os.path.join(DATASET_NOISES_PATH, folder),\n            )\n        else:\n            shutil.move(\n                os.path.join(dataset, folder),\n                os.path.join(DATASET_AUDIOS_PATH, folder),\n            )","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:00.865253Z","iopub.execute_input":"2022-12-23T10:19:00.865683Z","iopub.status.idle":"2022-12-23T10:19:00.900046Z","shell.execute_reply.started":"2022-12-23T10:19:00.865628Z","shell.execute_reply":"2022-12-23T10:19:00.899326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise_paths = []\nfor subdir in tf.io.gfile.listdir(DATASET_NOISES_PATH):\n    subdir_path = Path(DATASET_NOISES_PATH) / subdir\n    if os.path.isdir(subdir_path):\n        noise_paths += [\n            os.path.join(subdir_path, filepath)\n            for filepath in os.listdir(subdir_path)\n            if filepath.endswith(\".wav\")\n        ]\n\nprint(\n    \"Found {} files belonging to {} directories\".format(\n        len(noise_paths), len(os.listdir(DATASET_NOISES_PATH))\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:00.901203Z","iopub.execute_input":"2022-12-23T10:19:00.901974Z","iopub.status.idle":"2022-12-23T10:19:00.910308Z","shell.execute_reply.started":"2022-12-23T10:19:00.901936Z","shell.execute_reply":"2022-12-23T10:19:00.909397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convert all Noises to 16000HZ","metadata":{}},{"cell_type":"code","source":"command = (\n    \"for dir in `ls -1 \" + DATASET_NOISES_PATH + \"`; do \"\n    \"for file in `ls -1 \" + DATASET_NOISES_PATH + \"/$dir/*.wav`; do \"\n    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n    \"$file | grep sample_rate | cut -f2 -d=`; \"\n    \"if [ $sample_rate -ne 16000 ]; then \"\n    \"ffmpeg -hide_banner -loglevel panic -y \"\n    \"-i $file -ar 16000 temp.wav; \"\n    \"mv temp.wav $file; \"\n    \"fi; done; done\"\n)\n\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:00.911718Z","iopub.execute_input":"2022-12-23T10:19:00.912123Z","iopub.status.idle":"2022-12-23T10:19:02.414503Z","shell.execute_reply.started":"2022-12-23T10:19:00.912087Z","shell.execute_reply":"2022-12-23T10:19:02.413691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split noise into chunks of 16000 each","metadata":{}},{"cell_type":"code","source":"def load_noise_sample(path):\n    sample, sampling_rate = tf.audio.decode_wav(\n        tf.io.read_file(path), desired_channels=1\n    )\n    if sampling_rate == SAMPLING_RATE:\n        slices = int(sample.shape[0] / SAMPLING_RATE)\n        sample = tf.split(sample[: slices * SAMPLING_RATE], slices)\n        return sample\n    else:\n        print(\"Sampling rate for {} is incorrect. Ignoring it\".format(path))\n        return None","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:02.415906Z","iopub.execute_input":"2022-12-23T10:19:02.416389Z","iopub.status.idle":"2022-12-23T10:19:02.422486Z","shell.execute_reply.started":"2022-12-23T10:19:02.416354Z","shell.execute_reply":"2022-12-23T10:19:02.421568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noises = []\nfor path in noise_paths:\n    sample = load_noise_sample(path)\n    if sample:\n        noises.extend(sample)\nnoises = tf.stack(noises)\n\nprint(\n    \"{} noise files were split into {} noise samples where each is {} sec. long\".format(\n        len(noise_paths), noises.shape[0], noises.shape[1] // SAMPLING_RATE\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:02.424358Z","iopub.execute_input":"2022-12-23T10:19:02.424891Z","iopub.status.idle":"2022-12-23T10:19:06.279229Z","shell.execute_reply.started":"2022-12-23T10:19:02.424852Z","shell.execute_reply":"2022-12-23T10:19:06.278390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create Dataset","metadata":{}},{"cell_type":"code","source":"def paths_and_labels_to_dataset(audio_paths, labels):\n    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n    audio_ds = path_ds.map(lambda x : path_to_audio(x))\n    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n    return tf.data.Dataset.zip((audio_ds, label_ds))\n\n\ndef path_to_audio(path):\n    audio = tf.io.read_file(path)\n    audio, _ = tf.audio.decode_wav(audio, 1, SAMPLING_RATE)\n    return audio\n","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:06.282116Z","iopub.execute_input":"2022-12-23T10:19:06.282994Z","iopub.status.idle":"2022-12-23T10:19:06.289232Z","shell.execute_reply.started":"2022-12-23T10:19:06.282952Z","shell.execute_reply":"2022-12-23T10:19:06.288262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Add Noise","metadata":{}},{"cell_type":"code","source":"def add_noise(audio, noises=None, scale=0.5):\n    if noises is not None:\n        tf_rnd = tf.random.uniform(\n            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n        )\n        noise = tf.gather(noises, tf_rnd, axis=0)\n\n        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n\n        audio = audio + noise * prop * scale\n\n    return audio","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:06.290709Z","iopub.execute_input":"2022-12-23T10:19:06.291012Z","iopub.status.idle":"2022-12-23T10:19:06.305890Z","shell.execute_reply.started":"2022-12-23T10:19:06.290974Z","shell.execute_reply":"2022-12-23T10:19:06.305025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def audio_to_fft(audio):\n    audio = tf.squeeze(audio, axis=-1)\n    fft = tf.signal.fft(\n        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n    )\n    fft = tf.expand_dims(fft, axis=-1)\n\n    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:06.308552Z","iopub.execute_input":"2022-12-23T10:19:06.309043Z","iopub.status.idle":"2022-12-23T10:19:06.317935Z","shell.execute_reply.started":"2022-12-23T10:19:06.309012Z","shell.execute_reply":"2022-12-23T10:19:06.317263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = tf.io.gfile.listdir(DATASET_AUDIOS_PATH)\nprint(\"Our class names: {}\".format(class_names,))\n\naudio_paths = []\nlabels = []\n\nfor label, name in enumerate(class_names):\n    print(\"Processing speaker {}\".format(name,))\n    dir_path = Path(DATASET_AUDIOS_PATH) / name\n    speaker_sample_paths = [\n        os.path.join(dir_path, filepath)\n        for filepath in os.listdir(dir_path)\n        if filepath.endswith(\".wav\")\n    ]\n    audio_paths += speaker_sample_paths\n    labels += [label] * len(speaker_sample_paths)\n\nprint(labels)\n\nprint(\n    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:06.319365Z","iopub.execute_input":"2022-12-23T10:19:06.319629Z","iopub.status.idle":"2022-12-23T10:19:06.352991Z","shell.execute_reply.started":"2022-12-23T10:19:06.319593Z","shell.execute_reply":"2022-12-23T10:19:06.352125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rng = np.random.RandomState(SHUFFLE_SEED)\nrng.shuffle(audio_paths)\nrng = np.random.RandomState(SHUFFLE_SEED)\nrng.shuffle(labels)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:06.354584Z","iopub.execute_input":"2022-12-23T10:19:06.354882Z","iopub.status.idle":"2022-12-23T10:19:06.361341Z","shell.execute_reply.started":"2022-12-23T10:19:06.354846Z","shell.execute_reply":"2022-12-23T10:19:06.360384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split into training and validation","metadata":{}},{"cell_type":"code","source":"\nnum_val_samples = int(VALID_SPLIT * len(audio_paths))\nprint(\"Using {} files for training.\".format(len(audio_paths) - num_val_samples))\ntrain_audio_paths = audio_paths[:-num_val_samples]\ntrain_labels = labels[:-num_val_samples]\n\nprint(\"Using {} files for validation.\".format(num_val_samples))\nvalid_audio_paths = audio_paths[-num_val_samples:]\nvalid_labels = labels[-num_val_samples:]\n\n\n\n# Create 2 datasets, one for training and the other for validation\ntrain_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\ntrain_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n    BATCH_SIZE\n)\n\nvalid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\nvalid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:06.362773Z","iopub.execute_input":"2022-12-23T10:19:06.363276Z","iopub.status.idle":"2022-12-23T10:19:06.532514Z","shell.execute_reply.started":"2022-12-23T10:19:06.363237Z","shell.execute_reply":"2022-12-23T10:19:06.531742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature Extraction","metadata":{}},{"cell_type":"code","source":"# Add noise to the training set\ntrain_ds = train_ds.map(\n    lambda x, y: (add_noise(x, noises, scale=SCALE), y),\n    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n)\n\n# Transform audio wave to the frequency domain using `audio_to_fft`\ntrain_ds = train_ds.map(\n    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\n\ntrain_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n\nvalid_ds = valid_ds.map(\n    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\nvalid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:06.533986Z","iopub.execute_input":"2022-12-23T10:19:06.534236Z","iopub.status.idle":"2022-12-23T10:19:06.827121Z","shell.execute_reply.started":"2022-12-23T10:19:06.534203Z","shell.execute_reply":"2022-12-23T10:19:06.826319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create Model ","metadata":{}},{"cell_type":"code","source":"def residual_block(x, filters, conv_num=3, activation='relu'):\n    \n  s = keras.layers.Conv1D(filters, 1, padding='same')(x)\n  x = keras.layers.Conv1D(filters, 3, padding='same')(x)\n  x = keras.layers.Add()([x, s])\n  x = keras.layers.Activation(activation)(x)\n  return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n\n\ndef build_model(input_shape, num_classes):\n  inputs = keras.layers.Input(shape=input_shape, name='audio_input')\n  x = residual_block(inputs, 16, 2)\n  x = residual_block(x, 32, 2)\n  x = residual_block(x, 64, 3)\n  x = residual_block(x, 128, 3)\n\n  x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n  x = keras.layers.Flatten()(x)\n  x = keras.layers.Dense(256, activation=\"relu\")(x)\n  x = keras.layers.Dense(128, activation=\"relu\")(x)\n  outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n\n  return keras.models.Model(inputs=inputs, outputs=outputs)\n\n\nmodel = build_model((SAMPLING_RATE // 2, 1), len(class_names))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:06.828629Z","iopub.execute_input":"2022-12-23T10:19:06.828940Z","iopub.status.idle":"2022-12-23T10:19:07.022319Z","shell.execute_reply.started":"2022-12-23T10:19:06.828903Z","shell.execute_reply":"2022-12-23T10:19:07.021495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compile model and fit","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# CallBacks \ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")  # https://keras.io/api/callbacks/tensorboard/\nmodel_save_filename = \"model.h5\"\nearlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\nmdlcheckpoint_cb = keras.callbacks.ModelCheckpoint( model_save_filename, monitor='val_accuracy', save_best_only=True )","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:07.023568Z","iopub.execute_input":"2022-12-23T10:19:07.023847Z","iopub.status.idle":"2022-12-23T10:19:07.936662Z","shell.execute_reply.started":"2022-12-23T10:19:07.023797Z","shell.execute_reply":"2022-12-23T10:19:07.935866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    epochs=EPOCHS,\n    validation_data=valid_ds,\n    callbacks=[earlystopping_cb, mdlcheckpoint_cb, tensorboard_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:19:07.937947Z","iopub.execute_input":"2022-12-23T10:19:07.938377Z","iopub.status.idle":"2022-12-23T10:50:39.409253Z","shell.execute_reply.started":"2022-12-23T10:19:07.938335Z","shell.execute_reply":"2022-12-23T10:50:39.408465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy","metadata":{}},{"cell_type":"code","source":"print(\"Accuracy of model:\",model.evaluate(valid_ds))","metadata":{"execution":{"iopub.status.busy":"2022-12-23T10:50:39.411301Z","iopub.execute_input":"2022-12-23T10:50:39.411531Z","iopub.status.idle":"2022-12-23T10:50:46.425026Z","shell.execute_reply.started":"2022-12-23T10:50:39.411503Z","shell.execute_reply":"2022-12-23T10:50:46.424258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}